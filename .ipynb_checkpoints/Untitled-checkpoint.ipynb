{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\python38\\lib\\site-packages (0.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    '0' : ':orange_heart:',\n",
    "    '1' : ':baseball:',\n",
    "    '2' : ':grinning_face_with_big_eyes:',\n",
    "    '3' : ':downcast_face_with_sweat:',\n",
    "    '4' : ':fork_and_knife:'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß°\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòì\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-86ee238a5be5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python38\\lib\\site-packages (from keras) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python38\\lib\\site-packages (from keras) (1.19.3)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.3.1-cp38-cp38-win_amd64.whl (219 kB)\n",
      "Installing collected packages: pyyaml, h5py, keras\n",
      "Successfully installed h5py-3.1.0 keras-2.4.3 pyyaml-5.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-812bfb11e6e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\python38\\lib\\site-packages (from tensorflow) (1.19.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-py2.py3-none-any.whl (173 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (47.1.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "    Running setup.py install for wrapt: started\n",
      "    Running setup.py install for wrapt: finished with status 'done'\n",
      "    Running setup.py install for termcolor: started\n",
      "    Running setup.py install for termcolor: finished with status 'done'\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.2 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Datasets/train_emoji.csv',header = None)\n",
    "test = pd.read_csv('Datasets/test_emoji.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "X_test = test[0]\n",
    "Y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòì\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòì\n",
      "Miss you so much üß°\n",
      "food is life üç¥\n",
      "I love you mum üß°\n",
      "Stop saying bullshit üòì\n",
      "congratulations on your acceptance üòÉ\n",
      "The assignment is too long  üòì\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(X_train[i],emoji.emojize(emoji_dictionary[str(Y_train[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.6B.50d.txt',encoding='utf-8')\n",
    "embeddings_index = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen = 10\n",
    "    embedding_out = np.zeros((X.shape[0],maxLen,50))\n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix] = X[ix].split()\n",
    "        for jx in range(len(X[ix])):\n",
    "            embedding_out[ix][jx] = embeddings_index[X[ix][jx].lower()]\n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix_train = np.zeros((X_train.shape[0], 10, 50))\n",
    "embeddings_matrix_test = np.zeros((X_test.shape[0], 10, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n",
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_matrix_train.shape)\n",
    "print(embeddings_matrix_test.shape)\n",
    "Y_train = to_categorical(Y_train,num_classes=5)\n",
    "Y_test = to_categorical(Y_test,num_classes=5)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2/2 [==============================] - 22s 4s/step - loss: 1.6089 - accuracy: 0.1854 - val_loss: 1.6106 - val_accuracy: 0.1852\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.6035 - accuracy: 0.3293 - val_loss: 1.6124 - val_accuracy: 0.1852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.5963 - accuracy: 0.3345 - val_loss: 1.6150 - val_accuracy: 0.1852\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 1.5893 - accuracy: 0.3189 - val_loss: 1.6187 - val_accuracy: 0.1852\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 1.5819 - accuracy: 0.3189 - val_loss: 1.6239 - val_accuracy: 0.1852\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 1.5706 - accuracy: 0.3345 - val_loss: 1.6327 - val_accuracy: 0.1852\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.5629 - accuracy: 0.3137 - val_loss: 1.6472 - val_accuracy: 0.1852\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.5463 - accuracy: 0.3033 - val_loss: 1.6731 - val_accuracy: 0.1852\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 1.5376 - accuracy: 0.2981 - val_loss: 1.7180 - val_accuracy: 0.1852\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.5194 - accuracy: 0.3137 - val_loss: 1.7862 - val_accuracy: 0.1852\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 1.5400 - accuracy: 0.3033 - val_loss: 1.8323 - val_accuracy: 0.1852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 1.5475 - accuracy: 0.3137 - val_loss: 1.8292 - val_accuracy: 0.1852\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 1.5102 - accuracy: 0.3033 - val_loss: 1.8067 - val_accuracy: 0.1852\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.5075 - accuracy: 0.3062 - val_loss: 1.7762 - val_accuracy: 0.1852\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 265ms/step - loss: 1.5143 - accuracy: 0.3178 - val_loss: 1.7478 - val_accuracy: 0.1852\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 1.4949 - accuracy: 0.3420 - val_loss: 1.7297 - val_accuracy: 0.1852\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 1.5077 - accuracy: 0.3640 - val_loss: 1.7166 - val_accuracy: 0.1852\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.5049 - accuracy: 0.3882 - val_loss: 1.7096 - val_accuracy: 0.1852\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.5373 - accuracy: 0.3599 - val_loss: 1.7022 - val_accuracy: 0.2222\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.5314 - accuracy: 0.2536 - val_loss: 1.7003 - val_accuracy: 0.2222\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.5040 - accuracy: 0.3819 - val_loss: 1.7058 - val_accuracy: 0.2222\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 1.5203 - accuracy: 0.2969 - val_loss: 1.7132 - val_accuracy: 0.2222\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.5294 - accuracy: 0.3062 - val_loss: 1.7202 - val_accuracy: 0.2222\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 1.5138 - accuracy: 0.3166 - val_loss: 1.7288 - val_accuracy: 0.1852\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.5158 - accuracy: 0.3021 - val_loss: 1.7362 - val_accuracy: 0.1852\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.5239 - accuracy: 0.3148 - val_loss: 1.7404 - val_accuracy: 0.1852\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.5291 - accuracy: 0.2779 - val_loss: 1.7426 - val_accuracy: 0.1852\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.4930 - accuracy: 0.2946 - val_loss: 1.7504 - val_accuracy: 0.1852\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 275ms/step - loss: 1.5097 - accuracy: 0.2946 - val_loss: 1.7510 - val_accuracy: 0.1852\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.5272 - accuracy: 0.3484 - val_loss: 1.7484 - val_accuracy: 0.1852\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 1.5323 - accuracy: 0.3495 - val_loss: 1.7472 - val_accuracy: 0.1852\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 1.5342 - accuracy: 0.2940 - val_loss: 1.7469 - val_accuracy: 0.1852\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 1.5127 - accuracy: 0.3241 - val_loss: 1.7465 - val_accuracy: 0.1852\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 1.5222 - accuracy: 0.2929 - val_loss: 1.7462 - val_accuracy: 0.1852\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 1.5114 - accuracy: 0.3293 - val_loss: 1.7469 - val_accuracy: 0.1852\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 1.5067 - accuracy: 0.2958 - val_loss: 1.7460 - val_accuracy: 0.1852\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 1.5362 - accuracy: 0.3264 - val_loss: 1.7411 - val_accuracy: 0.1852\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 1.5335 - accuracy: 0.2854 - val_loss: 1.7417 - val_accuracy: 0.1852\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.5019 - accuracy: 0.3397 - val_loss: 1.7462 - val_accuracy: 0.1852\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 1.5317 - accuracy: 0.2929 - val_loss: 1.7478 - val_accuracy: 0.1852\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5',monitor='val_loss',verbose=True,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_acc',patience=10)\n",
    "hist = model.fit(embeddings_matrix_train,Y_train,epochs=40,batch_size=64,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5089 - accuracy: 0.3214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5089472532272339, 0.3214285671710968]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(embeddings_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I   w a n t   t o   e a t \t üòÉ\n",
      "h e   d i d   n o t   a n s w e r \t üòÉ\n",
      "h e   g o t   a   r a i s e \t üòÉ\n",
      "s h e   g o t   m e   a   p r e s e n t \t üòÉ\n",
      "h a   h a   h a   i t   w a s   s o   f u n n y \t üòÉ\n",
      "h e   i s   a   g o o d   f r i e n d \t üòÉ\n",
      "I   a m   u p s e t \t üòÉ\n",
      "W e   h a d   s u c h   a   l o v e l y   d i n n e r   t o n i g h t \t üòÉ\n",
      "w h e r e   i s   t h e   f o o d \t üòÉ\n",
      "S t o p   m a k i n g   t h i s   j o k e   h a   h a   h a \t üòÉ\n",
      "w h e r e   i s   t h e   b a l l \t üòÉ\n",
      "w o r k   i s   h a r d \t üòÉ\n",
      "T h i s   g i r l   i s   m e s s i n g   w i t h   m e \t üòÉ\n",
      "a r e   y o u   s e r i o u s   h a   h a \t üòÉ\n",
      "L e t   u s   g o   p l a y   b a s e b a l l \t üòÉ\n",
      "T h i s   s t u p i d   g r a d e r   i s   n o t   w o r k i n g   \t üòÉ\n",
      "w o r k   i s   h o r r i b l e \t üòÉ\n",
      "C o n g r a t u l a t i o n   f o r   h a v i n g   a   b a b y \t üòÉ\n",
      "s t o p   m e s s i n g   a r o u n d \t üòÉ\n",
      "a n y   s u g g e s t i o n s   f o r   d i n n e r \t üòÉ\n",
      "I   l o v e   t a k i n g   b r e a k s \t üòÉ\n",
      "y o u   b r i g h t e n   m y   d a y \t üòÉ\n",
      "I   b o i l e d   r i c e \t üòÉ\n",
      "s h e   i s   a   b u l l y \t üòÉ\n",
      "W h y   a r e   y o u   f e e l i n g   b a d \t üòÉ\n",
      "I   a m   u p s e t \t üòÉ\n",
      "I   w o r k e d   d u r i n g   m y   b i r t h d a y \t üòÉ\n",
      "M y   g r a n d m o t h e r   i s   t h e   l o v e   o f   m y   l i f e \t üòÉ\n",
      "e n j o y   y o u r   b r e a k \t üòÉ\n",
      "v a l e n t i n e   d a y   i s   n e a r \t üòÉ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(X_test[i]),end=\" \")\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize('food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß°\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòì\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
